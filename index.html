<!DOCTYPE html>
<!-- saved from url=(0023)https://jonbarron.info/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
    

    <title>Yazhen Yuan/袁亚振</title>

    <meta name="author" content="Yazhen Yuan">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="./images/stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text y=%22.9em%22 font-size=%2290%22&gt;%F0%9F%8C%90&lt;/text&gt;&lt;/svg&gt;">
  </head>

  <body data-new-gr-c-s-check-loaded="14.1126.0" data-gr-ext-installed="">
    <table style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Yazhen Yuan / 袁亚振
                </p>
                <p>I am a Principal Game Engine Developer (T12) working at Tencent in Hangzhou, where i focus on building an in-house engine from scratch.
                </p>
                <p>
                  I received my Ph.D. from CAD&CG National Key Lab@Zhejiang University, under the supervision by <a href="http://www.cad.zju.edu.cn/home/rwang/">Prof. Rui Wang</a> and <a href="http://www.cad.zju.edu.cn/home/bao/">Prof. Hujun Bao</a>. 
                </p>
                <p>My work and research experiences primarily focus on rendering and GPU technologies. Throughout my programming career, I have worked with various platforms and languages including PC, mobile, web, WeChat, VR/AR glasses, CG, GLSL, HLSL, and CUDA, among others. After graduation, I chose to work in the industry to gain exposure to different communities. However, I continue to stay updated on recent advances in academia and collaborate on exciting research projects in my spare time.</p>

                <p style="text-align:center">
                  <a href="mailto:835652868@qq.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=4EhxgBkAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                </p>
              </td>
              <td style="padding:2.5%;width:30%;max-width:40%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="./images/yyz.png" class="hoverZoomLink">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in Realtime rendering, Compute graphics, Artificial Intelligence.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


            <tr onmouseout="RobIR_stop()" onmouseover="RobIR_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="RobIR_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
                  <source src="images/zipnerf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src="./images/StreamingDenoising.png" width="256">
                </div>
                <script type="text/javascript">
                  function lmv_start() {
                    document.getElementById('RobIR_image').style.opacity = "1";
                  }
      
                  function lmv_stop() {
                    document.getElementById('RobIR_image').style.opacity = "0";
                  }
                  lmv_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">Streaming-Aware Neural Monte Carlo Rendering Framework with
                    Unified Denoising-Compression and Client Collaboration</span>
                <br>
                Hangming Fan, Yuchi Huo, Chuankun Zheng, Chonghao Hu, <strong>Yazhen Yuan</strong>, Rui Wang
                <br>
                <em>NeurIPS 2024</em>
                <br>
                <p></p>
                <p>
                For application of cloud rendering, we compress and denoise the noisy path-traced image at the same time during streaming
                </p>
              </td>
            </tr> 


            <tr onmouseout="RobIR_stop()" onmouseover="RobIR_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="RobIR_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
                  <source src="images/zipnerf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src="./images/MoFlow.png" width="256">
                </div>
                <script type="text/javascript">
                  function lmv_start() {
                    document.getElementById('RobIR_image').style.opacity = "1";
                  }
      
                  function lmv_stop() {
                    document.getElementById('RobIR_image').style.opacity = "0";
                  }
                  lmv_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">MoFlow: Motion-Guided Flows for Recurrent Rendered Frame Prediction</span>
                <br>
                Zhizhen Wu, Zhilong Yuan, Chenyu Zuo, <strong>Yazhen Yuan</strong>, Yifan PENG, Guiyang Pu, Rui Wang, Yuchi Huo
                <br>
                <em>NeurIPS 2024</em>
                <br>
                <p></p>
                <p>
                Faster and Better Future Frame Prediction
                </p>
              </td>
            </tr>  


            <tr onmouseout="RobIR_stop()" onmouseover="RobIR_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="RobIR_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
                  <source src="images/zipnerf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src="./images/MoFlow.png" width="256">
                </div>
                <script type="text/javascript">
                  function lmv_start() {
                    document.getElementById('RobIR_image').style.opacity = "1";
                  }
      
                  function lmv_stop() {
                    document.getElementById('RobIR_image').style.opacity = "0";
                  }
                  lmv_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">MoFlow: Motion-Guided Flows for Recurrent Rendered Frame Prediction</span>
                <br>
                Zhizhen Wu, Zhilong Yuan, Chenyu Zuo, <strong>Yazhen Yuan</strong>, Yifan PENG, Guiyang Pu, Rui Wang, Yuchi Huo
                <br>
                <em>NeurIPS 2024</em>
                <br>
                <p></p>
                <p>
                Faster and Better Future Frame Prediction
                </p>
              </td>
            </tr>  
          
            <tr onmouseout="RobIR_stop()" onmouseover="RobIR_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id="RobIR_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
                  <source src="images/zipnerf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src="./images/albedo.png" width="256">
                </div>
                <script type="text/javascript">
                  function lmv_start() {
                    document.getElementById('RobIR_image').style.opacity = "1";
                  }
      
                  function lmv_stop() {
                    document.getElementById('RobIR_image').style.opacity = "0";
                  }
                  lmv_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                  <span class="papertitle">RobIR: Robust Inverse Rendering for
                    High-Illumination Scenes</span>
                <br>
                <a href="https://ingra14m.github.io/">Ziyi Yang</a>,
                Yanzhen Chen,
                Xinyu Gao,
                <strong>Yazhen Yuan</strong>,
                Yu Wu,
                <a href="http://www.cad.zju.edu.cn/home/rwang/"> Xiaowei Zhou</a>,
                <a href="http://www.cad.zju.edu.cn/home/jin/"> Xiaogang Jin</a>
                <br>
                <em>NeurIPS 2024</em>
                <br>
                <p></p>
                <p>
                Recovering high-quality material maps from High-Illumination Scenes.
                </p>
              </td>
            </tr>  
    
      <tr onmouseout="lmv_stop()" onmouseover="lmv_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id="lmv_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
            <source src="images/zipnerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src="./images/LMV.png" width="256">
          </div>
          <script type="text/javascript">
            function lmv_start() {
              document.getElementById('lmv_image').style.opacity = "1";
            }

            function lmv_stop() {
              document.getElementById('lmv_image').style.opacity = "0";
            }
            lmv_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Adaptive Recurrent Frame Prediction with Learnable Motion
              Vectors</span>
          <br>
          Zhizhen Wu,
          Chenyu Zuo,
          Yuchi Huo,
          <strong>Yazhen Yuan</strong>,
          <a href="https://www.eee.hku.hk/~evanpeng/">Yifan Peng</a>,
          Guiyang Pu,
          <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>,
          <a href="http://www.cad.zju.edu.cn/home/rwang/">Hujun Bao</a>
          <br>
          <em>Siggrapha Asia</em>, 2023 &nbsp; (Conferences Track)
          <br>
          <p></p>
          <p>
          Using learned motion vector and recurrent feature to extrapolate multiple frames for realtime rendering.
          </p>
        </td>
      </tr>   
      
      <tr onmouseout="objmult_stop()" onmouseover="objmult_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id="objmult_image" style="opacity: 0;"><video width="100%" height="100%" muted="" autoplay="" loop="">
            <source src="images/zipnerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src="./images/objmult.webp" width="256">
          </div>
          <script type="text/javascript">
            function objmult_start() {
              document.getElementById('objmult_image').style.opacity = "1";
            }

            function objmult_stop() {
              document.getElementById('objmult_image').style.opacity = "0";
            }
            lmv_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Multirate Shading with Piecewise Interpolatory Approximation</span>
          <br>
          <a href="https://yiweihu.netlify.app/">Yiwei Hu</a>,
          <strong>Yazhen Yuan</strong>,
          <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>,
          Zhuo Yang,
          <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          Computer Graphics Forum, Proc. of Pacific Graphics (PG 2022).
          <br>
          <p></p>
          <p>
            We present a multirate shading approach via dynamic sparse sampling with piecewise linear reconstruction.
          </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/shaderTransformer.png" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">ShaderTransformer: Predicting Shader Quality via One-shot Embedding for Fast Simplification</span>
          <br>
          Yuchi Huo, Shi Li, <strong>Yazhen Yuan</strong>, Xu Chen, <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, Wenting Zheng, H Lin, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          <em>Siggrapha</em>, 2022 &nbsp; (Conferences Track)
          <br>
          <p>We use transformer to predict visual impact of shader’s variables and expressions for fast shader code simplification. </p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/tilepair.png" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Tile pair-based adaptive multi-rate stereo shading</span>
          <br>
          <strong>Yazhen Yuan</strong>, <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          <em>IEEE Transactions on Visualization and Computer Graphics </em>, 2018 &nbsp; (IEEE VR 2019)
          <br>
          <p>We found an useful tile pair structure and design a new gpu pipeline for efficient vr rendering. </p>
        </td>
      </tr>
        
      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/runtime_opt.png" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Runtime shader simplification via instant search in reduced optimization space</span>
          <br>
          <strong>Yazhen Yuan</strong>, <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, Tianlei Hu, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          <em>Computer Graphics Forum </em>, 2018 &nbsp; Proc. of Euro Graphics Symposium of Rendering (EGSR 2018)
          <br>
          <p>We construct a graph to analysis relations between shader code variants, and search for fastest simplified shader during runtime. </p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/simp_and_tess.png" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Simplified and tessellated mesh for realtime high quality rendering</span>
          <br>
          <strong>Yazhen Yuan</strong>, <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, Jing Huang, Jiaya Jia, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          <em>Computers & Graphics  </em>, 2015 &nbsp; Proc. of CAD&Graphics 2015
          <br>
          <p>For tessellation shader, we design a new mesh simplification and reconstruction method to render mesh with complexity geometry.</p>
        </td>
      </tr>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/auto.png" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">Automatic shader simplification using surface signal approximation</span>
          <br>
          <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, <a href="https://yangx0e.github.io/">Xianjin Yang</a>, <strong>Yazhen Yuan</strong>, Wei Chen, Kavita Bala, <a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          ACM Transactions on Graphics, Proceedings of ACM SIGGRAPH ASIA, 2014
          <br>
          <p>We can move shader code to different shader stages to find the optimal shader code variants.</p>
        </td>
      </tr>


      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
          <img src="./images/gpu.jfif" alt="prl" width="256">
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
            <span class="papertitle">GPU-based out-of-core many-lights rendering</span>
          <br>
          <a href="http://www.cad.zju.edu.cn/home/rwang/">Rui Wang</a>, Yuchi Huo, <strong>Yazhen Yuan</strong>, Kun Zhou, Wei Hua,<a href="http://www.cad.zju.edu.cn/home/bao/">Hujun Bao</a>
          <br>
          ACM Transactions on Graphics, Proceedings of ACM SIGGRAPH ASIA, 2013
          <br>
          <p>We can render billions of lights on a single GPU.</p>
        </td>
      </tr>

  

</body><grammarly-desktop-integration data-grammarly-shadow-root="true"><template shadowrootmode="open"><style>
      div.grammarly-desktop-integration {
        position: absolute;
        width: 1px;
        height: 1px;
        padding: 0;
        margin: -1px;
        overflow: hidden;
        clip: rect(0, 0, 0, 0);
        white-space: nowrap;
        border: 0;
        -moz-user-select: none;
        -webkit-user-select: none;
        -ms-user-select:none;
        user-select:none;
      }

      div.grammarly-desktop-integration:before {
        content: attr(data-content);
      }
    </style><div aria-label="grammarly-integration" role="group" tabindex="-1" class="grammarly-desktop-integration" data-content="{&quot;mode&quot;:&quot;full&quot;,&quot;isActive&quot;:true,&quot;isUserDisabled&quot;:false}"></div></template></grammarly-desktop-integration></html>
